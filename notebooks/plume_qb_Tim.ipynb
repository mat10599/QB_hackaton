{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import EfficientNetB0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 64\n",
    "image_width = 64\n",
    "batch_size = 20\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id_coord</th>\n",
       "      <th>plume</th>\n",
       "      <th>set</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>coord_x</th>\n",
       "      <th>coord_y</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230223</td>\n",
       "      <td>id_6675</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>31.528750</td>\n",
       "      <td>74.330625</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>train_data/images/plume/20230223_methane_mixin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230103</td>\n",
       "      <td>id_2542</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>35.538000</td>\n",
       "      <td>112.524000</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>train_data/images/plume/20230103_methane_mixin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230301</td>\n",
       "      <td>id_6546</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>21.060000</td>\n",
       "      <td>84.936667</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>train_data/images/plume/20230301_methane_mixin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230225</td>\n",
       "      <td>id_6084</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>26.756667</td>\n",
       "      <td>80.973333</td>\n",
       "      <td>28</td>\n",
       "      <td>62</td>\n",
       "      <td>train_data/images/plume/20230225_methane_mixin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230105</td>\n",
       "      <td>id_2012</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>34.800000</td>\n",
       "      <td>40.770000</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>train_data/images/plume/20230105_methane_mixin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date id_coord plume    set        lat         lon  coord_x  coord_y  \\\n",
       "0  20230223  id_6675   yes  train  31.528750   74.330625       24       47   \n",
       "1  20230103  id_2542   yes  train  35.538000  112.524000       42       37   \n",
       "2  20230301  id_6546   yes  train  21.060000   84.936667       58       15   \n",
       "3  20230225  id_6084   yes  train  26.756667   80.973333       28       62   \n",
       "4  20230105  id_2012   yes  train  34.800000   40.770000       59       44   \n",
       "\n",
       "                                                path  \n",
       "0  train_data/images/plume/20230223_methane_mixin...  \n",
       "1  train_data/images/plume/20230103_methane_mixin...  \n",
       "2  train_data/images/plume/20230301_methane_mixin...  \n",
       "3  train_data/images/plume/20230225_methane_mixin...  \n",
       "4  train_data/images/plume/20230105_methane_mixin...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('/Users/Timothe/Documents/DSB/QB/data/train_data/metadata.csv')\n",
    "df[\"path\"] = \"train_data/\" + df[\"path\"] + \".tif\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_df, valid_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(valid_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess images\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    image = Image.open(row['path'])\n",
    "    image = image.resize((image_height, image_width))\n",
    "    image = np.array(image) / 255.0  # Rescale pixel values to [0, 1]\n",
    "    train_images.append(image)\n",
    "    train_labels.append(row['plume'])\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "validation_images = [] \n",
    "validation_labels = []\n",
    "\n",
    "for index, row in val_df.iterrows():\n",
    "    image = Image.open(row['path'])\n",
    "    image = image.resize((image_height, image_width))\n",
    "    image = np.array(image) / 255.0  # Rescale pixel values to [0, 1]\n",
    "    validation_images.append(image)\n",
    "    validation_labels.append(row['plume'])\n",
    "\n",
    "validation_images = np.array(validation_images)\n",
    "validation_labels = np.array(validation_labels)\n",
    "\n",
    "test_images = []  # Load and preprocess test images similarly\n",
    "test_labels = []\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    image = Image.open(row['path'])\n",
    "    image = image.resize((image_height, image_width))\n",
    "    image = np.array(image) / 255.0  # Rescale pixel values to [0, 1]\n",
    "    test_images.append(image)\n",
    "    test_labels.append(row['plume'])\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string labels to numerical format in your data frames\n",
    "train_df['plume'] = train_df['plume'].map({'yes': 1, 'no': 0})\n",
    "val_df['plume'] = val_df['plume'].map({'yes': 1, 'no': 0})\n",
    "test_df['plume'] = test_df['plume'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Now convert the labels to NumPy arrays\n",
    "train_labels = np.array(train_df['plume'])\n",
    "validation_labels = np.array(val_df['plume'])\n",
    "test_labels = np.array(test_df['plume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "10/10 [==============================] - 2s 103ms/step - loss: 8.9623 - auc: 0.4972 - val_loss: 0.7326 - val_auc: 0.8651\n",
      "Epoch 2/15\n",
      "10/10 [==============================] - 1s 67ms/step - loss: 0.8028 - auc: 0.5986 - val_loss: 0.6146 - val_auc: 0.8272\n",
      "Epoch 3/15\n",
      "10/10 [==============================] - 1s 68ms/step - loss: 0.6147 - auc: 0.7156 - val_loss: 0.6499 - val_auc: 0.8651\n",
      "Epoch 4/15\n",
      "10/10 [==============================] - 1s 68ms/step - loss: 0.5083 - auc: 0.8655 - val_loss: 0.5286 - val_auc: 0.7790\n",
      "Epoch 5/15\n",
      "10/10 [==============================] - 1s 67ms/step - loss: 0.4379 - auc: 0.8957 - val_loss: 0.4900 - val_auc: 0.8221\n",
      "Epoch 6/15\n",
      "10/10 [==============================] - 1s 68ms/step - loss: 0.3368 - auc: 0.9310 - val_loss: 0.4876 - val_auc: 0.8703\n",
      "Epoch 7/15\n",
      "10/10 [==============================] - 1s 68ms/step - loss: 0.2545 - auc: 0.9664 - val_loss: 0.4693 - val_auc: 0.8754\n",
      "Epoch 8/15\n",
      "10/10 [==============================] - 1s 66ms/step - loss: 0.2019 - auc: 0.9764 - val_loss: 0.7549 - val_auc: 0.9056\n",
      "Epoch 9/15\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 0.1873 - auc: 0.9812 - val_loss: 0.6456 - val_auc: 0.8523\n",
      "Epoch 10/15\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 0.1492 - auc: 0.9881 - val_loss: 0.5850 - val_auc: 0.8667\n",
      "Epoch 11/15\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.0813 - auc: 0.9973 - val_loss: 0.6725 - val_auc: 0.8446\n",
      "Epoch 12/15\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 0.0911 - auc: 0.9914 - val_loss: 0.5993 - val_auc: 0.8769\n",
      "Epoch 13/15\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.0686 - auc: 0.9980 - val_loss: 0.7453 - val_auc: 0.8826\n",
      "Epoch 14/15\n",
      "10/10 [==============================] - 1s 83ms/step - loss: 0.0450 - auc: 0.9993 - val_loss: 0.6208 - val_auc: 0.8800\n",
      "Epoch 15/15\n",
      "10/10 [==============================] - 1s 83ms/step - loss: 0.0763 - auc: 0.9973 - val_loss: 0.6864 - val_auc: 0.8626\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9422 - auc: 0.8079\n",
      "Test accuracy: 0.8078747391700745\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, 1)))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "# Flatten the feature maps\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 15  # Adjust the number of training epochs as needed\n",
    "model.fit(train_images, train_labels, validation_data=(validation_images, validation_labels), epochs=epochs)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(\"Test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rescale=1./255  # Rescale pixel values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape + (1,))\n",
    "train_datagen = datagen.flow(train_images, train_labels, batch_size=batch_size)\n",
    "validation_images = validation_images.reshape(validation_images.shape + (1,))\n",
    "validation_datagen = datagen.flow(validation_images, validation_labels, batch_size=batch_size)\n",
    "test_images = test_images.reshape(test_images.shape + (1,))\n",
    "test_datagen = datagen.flow(test_images, test_labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "10/10 [==============================] - 4s 138ms/step - loss: 0.6964 - auc: 0.5789 - val_loss: 0.6901 - val_auc: 0.8410\n",
      "Epoch 2/15\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.6745 - auc: 0.6624 - val_loss: 0.7232 - val_auc: 0.8723\n",
      "Epoch 3/15\n",
      "10/10 [==============================] - 1s 86ms/step - loss: 0.6595 - auc: 0.7512 - val_loss: 0.6702 - val_auc: 0.8949\n",
      "Epoch 4/15\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 0.6309 - auc: 0.8104 - val_loss: 0.6423 - val_auc: 0.8703\n",
      "Epoch 5/15\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 0.6160 - auc: 0.8048 - val_loss: 0.6080 - val_auc: 0.8923\n",
      "Epoch 6/15\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 0.6344 - auc: 0.7223 - val_loss: 0.6731 - val_auc: 0.9287\n",
      "Epoch 7/15\n",
      "10/10 [==============================] - 1s 80ms/step - loss: 0.6175 - auc: 0.7542 - val_loss: 0.5511 - val_auc: 0.9031\n",
      "Epoch 8/15\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 0.5513 - auc: 0.8402 - val_loss: 0.4683 - val_auc: 0.9215\n",
      "Epoch 9/15\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.5221 - auc: 0.8341 - val_loss: 0.5208 - val_auc: 0.9200\n",
      "Epoch 10/15\n",
      "10/10 [==============================] - 1s 85ms/step - loss: 0.4935 - auc: 0.8473 - val_loss: 0.5648 - val_auc: 0.9046\n",
      "Epoch 11/15\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.4860 - auc: 0.8549 - val_loss: 0.4280 - val_auc: 0.9072\n",
      "Epoch 12/15\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.4916 - auc: 0.8444 - val_loss: 0.4264 - val_auc: 0.9077\n",
      "Epoch 13/15\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.4680 - auc: 0.8583 - val_loss: 0.5735 - val_auc: 0.9031\n",
      "Epoch 14/15\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 0.4478 - auc: 0.8723 - val_loss: 0.4232 - val_auc: 0.8841\n",
      "Epoch 15/15\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.4862 - auc: 0.8429 - val_loss: 0.3872 - val_auc: 0.9405\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5858 - auc: 0.8226\n",
      "Test accuracy: 0.8225806355476379\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, 1)))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "# Flatten the feature maps\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 15  # Adjust the number of training epochs as needed\n",
    "model.fit(train_datagen, validation_data=validation_datagen, epochs=epochs)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_datagen)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_df, valid_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(valid_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess images\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    image = Image.open(row['path']).convert('RGB')\n",
    "    image = image.resize((image_height, image_width))\n",
    "    image = np.array(image) / 255.0  # Rescale pixel values to [0, 1]\n",
    "    train_images.append(image)\n",
    "    train_labels.append(row['plume'])\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "validation_images = [] \n",
    "validation_labels = []\n",
    "\n",
    "for index, row in val_df.iterrows():\n",
    "    image = Image.open(row['path']).convert('RGB')\n",
    "    image = image.resize((image_height, image_width))\n",
    "    image = np.array(image) / 255.0  # Rescale pixel values to [0, 1]\n",
    "    validation_images.append(image)\n",
    "    validation_labels.append(row['plume'])\n",
    "\n",
    "validation_images = np.array(validation_images)\n",
    "validation_labels = np.array(validation_labels)\n",
    "\n",
    "test_images = []  # Load and preprocess test images similarly\n",
    "test_labels = []\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    image = Image.open(row['path']).convert('RGB')\n",
    "    image = image.resize((image_height, image_width))\n",
    "    image = np.array(image) / 255.0  # Rescale pixel values to [0, 1]\n",
    "    test_images.append(image)\n",
    "    test_labels.append(row['plume'])\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(pretrained_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Freeze the pre-trained layers for fine-tuning\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 8s 492ms/step - loss: 0.6666 - auc: 0.6491 - val_loss: 0.5878 - val_auc: 0.8149\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.5026 - auc: 0.8408 - val_loss: 0.5112 - val_auc: 0.8615\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 5s 497ms/step - loss: 0.4290 - auc: 0.8982 - val_loss: 0.5442 - val_auc: 0.9005\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 5s 483ms/step - loss: 0.3905 - auc: 0.9201 - val_loss: 0.6095 - val_auc: 0.9087\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 5s 461ms/step - loss: 0.3559 - auc: 0.9343 - val_loss: 0.4722 - val_auc: 0.9087\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 5s 463ms/step - loss: 0.2947 - auc: 0.9689 - val_loss: 0.4437 - val_auc: 0.9097\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 5s 469ms/step - loss: 0.2618 - auc: 0.9786 - val_loss: 0.3999 - val_auc: 0.9087\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 5s 481ms/step - loss: 0.2316 - auc: 0.9871 - val_loss: 0.4058 - val_auc: 0.9133\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 5s 472ms/step - loss: 0.2040 - auc: 0.9899 - val_loss: 0.4917 - val_auc: 0.9179\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 5s 484ms/step - loss: 0.1801 - auc: 0.9942 - val_loss: 0.5710 - val_auc: 0.9108\n",
      "3/3 [==============================] - 2s 238ms/step - loss: 0.6529 - auc: 0.8269\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "history = model.fit(train_images, \n",
    "                    train_labels,  \n",
    "                    validation_data=(validation_images, validation_labels), \n",
    "                    epochs=num_epochs)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 6s 444ms/step - loss: 0.6749 - auc: 0.6394 - val_loss: 0.5057 - val_auc: 0.8523\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 4s 429ms/step - loss: 0.5163 - auc: 0.8188 - val_loss: 0.4485 - val_auc: 0.8779\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 4s 450ms/step - loss: 0.4332 - auc: 0.8851 - val_loss: 0.4281 - val_auc: 0.8933\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 5s 508ms/step - loss: 0.3680 - auc: 0.9399 - val_loss: 0.4976 - val_auc: 0.9159\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 6s 653ms/step - loss: 0.3316 - auc: 0.9508 - val_loss: 0.4982 - val_auc: 0.9164\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 4s 408ms/step - loss: 0.2892 - auc: 0.9698 - val_loss: 0.4808 - val_auc: 0.9164\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 4s 429ms/step - loss: 0.2467 - auc: 0.9816 - val_loss: 0.4673 - val_auc: 0.9226\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 5s 498ms/step - loss: 0.2149 - auc: 0.9891 - val_loss: 0.6655 - val_auc: 0.9103\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 5s 504ms/step - loss: 0.2258 - auc: 0.9773 - val_loss: 0.5462 - val_auc: 0.9231\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 5s 498ms/step - loss: 0.2567 - auc: 0.9644 - val_loss: 0.5170 - val_auc: 0.9308\n",
      "3/3 [==============================] - 2s 229ms/step - loss: 0.6040 - auc: 0.8292\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained EfficientNetB0 model\n",
    "pretrained_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(pretrained_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Freeze the pre-trained layers for fine-tuning\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Freeze the pre-trained layers for fine-tuning\n",
    "for layer in pretrained_model2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "history = model.fit(train_images, \n",
    "                    train_labels,\n",
    "                    validation_data=(validation_images, validation_labels), \n",
    "                    epochs=num_epochs)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 17:26:31.024014: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at conv_ops_fused_impl.h:761 : INVALID_ARGUMENT: input depth must be evenly divisible by filter depth: 1 vs 3\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_35/vgg16/block1_conv1/Relu defined at (most recent call last):\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/tornado/platform/asyncio.py\", line 215, in start\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n\n  File \"/var/folders/01/9tpdzz9j1sz8x8fmb76s_qz40000gn/T/ipykernel_17889/3645883437.py\", line 20, in <module>\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1126, in train_step\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 589, in __call__\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/sequential.py\", line 398, in call\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 589, in __call__\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/layers/convolutional/base_conv.py\", line 321, in call\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/activations.py\", line 306, in relu\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/backend.py\", line 5397, in relu\n\ninput depth must be evenly divisible by filter depth: 1 vs 3\n\t [[{{node sequential_35/vgg16/block1_conv1/Relu}}]] [Op:__inference_train_function_216740]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [170], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m     layer\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     18\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mAUC\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 20\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_datagen,\n\u001b[1;32m     21\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mvalidation_datagen, \n\u001b[1;32m     22\u001b[0m                     epochs\u001b[39m=\u001b[39;49mnum_epochs)\n\u001b[1;32m     24\u001b[0m test_loss, test_accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(test_datagen)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential_35/vgg16/block1_conv1/Relu defined at (most recent call last):\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/tornado/platform/asyncio.py\", line 215, in start\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n\n  File \"/var/folders/01/9tpdzz9j1sz8x8fmb76s_qz40000gn/T/ipykernel_17889/3645883437.py\", line 20, in <module>\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1126, in train_step\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 589, in __call__\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/sequential.py\", line 398, in call\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 589, in __call__\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/layers/convolutional/base_conv.py\", line 321, in call\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/activations.py\", line 306, in relu\n\n  File \"/Users/Timothe/Library/Python/3.9/lib/python/site-packages/keras/src/backend.py\", line 5397, in relu\n\ninput depth must be evenly divisible by filter depth: 1 vs 3\n\t [[{{node sequential_35/vgg16/block1_conv1/Relu}}]] [Op:__inference_train_function_216740]"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained EfficientNetB0 model\n",
    "pretrained_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(pretrained_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Freeze the pre-trained layers for fine-tuning\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Freeze the pre-trained layers for fine-tuning\n",
    "for layer in pretrained_model2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "history = model.fit(train_datagen,\n",
    "                    validation_data=validation_datagen, \n",
    "                    epochs=num_epochs)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_datagen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
