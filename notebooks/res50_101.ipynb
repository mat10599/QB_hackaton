{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cVyW-hLt_-No"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import scipy.optimize\n",
        "import scipy\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset,random_split\n",
        "from sklearn.metrics import classification_report, f1_score, roc_auc_score\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEhk33oEA_kt",
        "outputId": "848b4e56-2516-41e8-acbb-7583d9702bfb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CENeg6go_-Np",
        "outputId": "ee2c73a7-ff3d-421e-df3e-e8ebb48df3ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       date id_coord plume    set        lat         lon  coord_x  coord_y  \\\n",
              "0  20230223  id_6675   yes  train  31.528750   74.330625       24       47   \n",
              "1  20230103  id_2542   yes  train  35.538000  112.524000       42       37   \n",
              "2  20230301  id_6546   yes  train  21.060000   84.936667       58       15   \n",
              "3  20230225  id_6084   yes  train  26.756667   80.973333       28       62   \n",
              "4  20230105  id_2012   yes  train  34.800000   40.770000       59       44   \n",
              "\n",
              "                                                path  \n",
              "0  images/plume/20230223_methane_mixing_ratio_id_...  \n",
              "1  images/plume/20230103_methane_mixing_ratio_id_...  \n",
              "2  images/plume/20230301_methane_mixing_ratio_id_...  \n",
              "3  images/plume/20230225_methane_mixing_ratio_id_...  \n",
              "4  images/plume/20230105_methane_mixing_ratio_id_...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-763cb3db-4516-4412-88b4-93d27a520db5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>id_coord</th>\n",
              "      <th>plume</th>\n",
              "      <th>set</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>coord_x</th>\n",
              "      <th>coord_y</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20230223</td>\n",
              "      <td>id_6675</td>\n",
              "      <td>yes</td>\n",
              "      <td>train</td>\n",
              "      <td>31.528750</td>\n",
              "      <td>74.330625</td>\n",
              "      <td>24</td>\n",
              "      <td>47</td>\n",
              "      <td>images/plume/20230223_methane_mixing_ratio_id_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20230103</td>\n",
              "      <td>id_2542</td>\n",
              "      <td>yes</td>\n",
              "      <td>train</td>\n",
              "      <td>35.538000</td>\n",
              "      <td>112.524000</td>\n",
              "      <td>42</td>\n",
              "      <td>37</td>\n",
              "      <td>images/plume/20230103_methane_mixing_ratio_id_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20230301</td>\n",
              "      <td>id_6546</td>\n",
              "      <td>yes</td>\n",
              "      <td>train</td>\n",
              "      <td>21.060000</td>\n",
              "      <td>84.936667</td>\n",
              "      <td>58</td>\n",
              "      <td>15</td>\n",
              "      <td>images/plume/20230301_methane_mixing_ratio_id_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20230225</td>\n",
              "      <td>id_6084</td>\n",
              "      <td>yes</td>\n",
              "      <td>train</td>\n",
              "      <td>26.756667</td>\n",
              "      <td>80.973333</td>\n",
              "      <td>28</td>\n",
              "      <td>62</td>\n",
              "      <td>images/plume/20230225_methane_mixing_ratio_id_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20230105</td>\n",
              "      <td>id_2012</td>\n",
              "      <td>yes</td>\n",
              "      <td>train</td>\n",
              "      <td>34.800000</td>\n",
              "      <td>40.770000</td>\n",
              "      <td>59</td>\n",
              "      <td>44</td>\n",
              "      <td>images/plume/20230105_methane_mixing_ratio_id_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-763cb3db-4516-4412-88b4-93d27a520db5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-763cb3db-4516-4412-88b4-93d27a520db5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-763cb3db-4516-4412-88b4-93d27a520db5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cb9330b5-652a-4481-bad8-2775888cad87\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb9330b5-652a-4481-bad8-2775888cad87')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cb9330b5-652a-4481-bad8-2775888cad87 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Load the data\n",
        "df = pd.read_csv('/content/drive/My Drive/data/train data/metadata.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1yIzDTUK_-Np"
      },
      "outputs": [],
      "source": [
        "# Split the data\n",
        "#train_df, valid_df = train_test_split(df, train_size =0.8, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into 3 parts\n",
        "train_df, val_df = train_test_split(df, test_size=0.3, random_state=42)\n",
        "valid_df, test_df = train_test_split(val_df, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "b05NZ09EZHgU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract file names from path\n",
        "train_df['new_path'] = train_df['path'].str.replace(r'images/(plume|no_plume)/', '', regex=True) + \".tif\"\n",
        "valid_df['new_path'] = valid_df['path'].str.replace(r'images/(plume|no_plume)/', '', regex=True) + \".tif\"\n",
        "test_df['new_path'] = test_df['path'].str.replace(r'images/(plume|no_plume)/', '', regex=True) + \".tif\""
      ],
      "metadata": {
        "id": "6QkRB9hlsiZH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For each train and validation datasets seggregate data into separate folders based on plume or no plume\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Set up paths\n",
        "data_dir = '/content/drive/My Drive/data/train data/images'\n",
        "train_dir= 'train'\n",
        "val_dir = 'validation'\n",
        "test_dir = 'test'\n",
        "\n",
        "plume_dir = 'plume'\n",
        "no_plume_dir = 'no_plume'\n",
        "\n",
        "# Create validation directories\n",
        "os.makedirs(os.path.join(train_dir, plume_dir), exist_ok=True)\n",
        "os.makedirs(os.path.join(train_dir, no_plume_dir), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, plume_dir), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, no_plume_dir), exist_ok=True)\n",
        "os.makedirs(os.path.join(test_dir, plume_dir), exist_ok=True)\n",
        "os.makedirs(os.path.join(test_dir, no_plume_dir), exist_ok=True)\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    image_file = row['new_path']\n",
        "    is_plume = row['plume']\n",
        "\n",
        "    if is_plume == 'yes':\n",
        "      if not os.path.exists(os.path.join(train_dir, plume_dir, image_file)):\n",
        "        shutil.move(os.path.join(data_dir, plume_dir, image_file),\n",
        "                os.path.join(train_dir, plume_dir))\n",
        "    else:\n",
        "      if not os.path.exists(os.path.join(train_dir, no_plume_dir, image_file)):\n",
        "        shutil.move(os.path.join(data_dir, no_plume_dir, image_file),\n",
        "                os.path.join(train_dir, no_plume_dir))\n",
        "\n",
        "for index, row in valid_df.iterrows():\n",
        "    image_file = row['new_path']\n",
        "    is_plume = row['plume']\n",
        "\n",
        "    if is_plume == 'yes':\n",
        "      if not os.path.exists(os.path.join(val_dir, plume_dir, image_file)):\n",
        "        shutil.move(os.path.join(data_dir, plume_dir, image_file),\n",
        "                os.path.join(val_dir, plume_dir))\n",
        "    else:\n",
        "      if not os.path.exists(os.path.join(val_dir, no_plume_dir, image_file)):\n",
        "        shutil.move(os.path.join(data_dir, no_plume_dir, image_file),\n",
        "                os.path.join(val_dir, no_plume_dir))\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_file = row['new_path']\n",
        "    is_plume = row['plume']\n",
        "\n",
        "    if is_plume == 'yes':\n",
        "      if not os.path.exists(os.path.join(test_dir, plume_dir, image_file)):\n",
        "        shutil.move(os.path.join(data_dir, plume_dir, image_file),\n",
        "                os.path.join(test_dir, plume_dir))\n",
        "    else:\n",
        "      if not os.path.exists(os.path.join(test_dir, no_plume_dir, image_file)):\n",
        "        shutil.move(os.path.join(data_dir, no_plume_dir, image_file),\n",
        "                os.path.join(test_dir, no_plume_dir))"
      ],
      "metadata": {
        "id": "rKVB-yjtp8u3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, augment=False):\n",
        "        self.root_dir = root_dir\n",
        "        self.augment = augment\n",
        "        self.image_list = []\n",
        "        self.labels = []\n",
        "        self.augmented_images = []\n",
        "\n",
        "        plume_images = []\n",
        "        no_plume_images = []\n",
        "\n",
        "        classes = os.listdir(root_dir)\n",
        "        for class_name in classes:\n",
        "            class_dir = os.path.join(root_dir, class_name)\n",
        "            if os.path.isdir(class_dir):\n",
        "                image_names = os.listdir(class_dir)\n",
        "                tiff_image_names = [img_name for img_name in image_names if img_name.lower().endswith('.tiff') or img_name.lower().endswith('.tif')]\n",
        "\n",
        "                if class_name == 'plume':\n",
        "                    plume_images.extend([os.path.join(class_dir, img_name) for img_name in tiff_image_names])\n",
        "                else:\n",
        "                    no_plume_images.extend([os.path.join(class_dir, img_name) for img_name in tiff_image_names])\n",
        "\n",
        "                self.labels.extend([1 if class_name == 'plume' else 0] * len(tiff_image_names))\n",
        "\n",
        "        # Calculate the number of images in each class\n",
        "        num_images = min(len(plume_images), len(no_plume_images))\n",
        "\n",
        "        if augment:\n",
        "            augmented_images = []\n",
        "            for _ in range(num_images):\n",
        "                # Randomly select plume and no plume images\n",
        "                plume_image_path = random.choice(plume_images)\n",
        "                no_plume_image_path = random.choice(no_plume_images)\n",
        "\n",
        "                # Load and augment plume image\n",
        "                plume_image = Image.open(plume_image_path)\n",
        "                plume_image = plume_image.resize((64, 64))  # Resize to 64x64\n",
        "                transform = transforms.Compose([\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.RandomRotation(10),\n",
        "                    transforms.ToTensor()\n",
        "                ])\n",
        "                augmented_plume_image = transform(plume_image)\n",
        "                augmented_images.append(augmented_plume_image)\n",
        "\n",
        "                # Load and augment no plume image\n",
        "                no_plume_image = Image.open(no_plume_image_path)\n",
        "                no_plume_image = no_plume_image.resize((64, 64))  # Resize to 64x64\n",
        "                augmented_no_plume_image = transform(no_plume_image)\n",
        "                augmented_images.append(augmented_no_plume_image)\n",
        "\n",
        "            self.augmented_images = augmented_images\n",
        "\n",
        "        self.image_list = plume_images[:num_images] + no_plume_images[:num_images]\n",
        "        self.labels = [1] * num_images + [0] * num_images\n",
        "\n",
        "        if augment:\n",
        "            num_augmented_images = len(self.augmented_images)\n",
        "            self.image_list.extend(self.augmented_images)\n",
        "            self.labels.extend(self.labels[:num_augmented_images])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.image_list[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if isinstance(image, str):\n",
        "            image = Image.open(image)\n",
        "            image = image.resize((64, 64))  # Resize to 64x64\n",
        "\n",
        "            transform = transforms.Compose([\n",
        "                transforms.ToTensor()\n",
        "            ])\n",
        "            image = transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "In1ohH-hyw6P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = \"train\"\n",
        "val_dir = \"validation\"\n",
        "\n",
        "train_dataset = CustomDataset(root_dir, augment=True)\n",
        "val_dataset = CustomDataset(val_dir, augment=False)\n",
        "test_dataset = CustomDataset(test_dir, augment=False)\n",
        "\n",
        "# Define batch size for training and validation\n",
        "batch_size = 32\n",
        "\n",
        "# Create the train DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Create the validation DataLoader\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# Create the validation DataLoader\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "# Verify the train and validation data loaders\n",
        "for images, labels in train_loader:\n",
        "    print(f\"Train batch - Images: {images.shape}, Labels: {labels.shape}\")\n",
        "    break\n",
        "\n",
        "for images, labels in val_loader:\n",
        "    print(f\"Validation batch - Images: {images.shape}, Labels: {labels.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e01KB22pyxLc",
        "outputId": "bca46047-ccea-4493-9513-699922140971"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train batch - Images: torch.Size([32, 1, 64, 64]), Labels: torch.Size([32])\n",
            "Validation batch - Images: torch.Size([32, 1, 64, 64]), Labels: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We can check that our train dataset is balanced between plume and no plume\n",
        "num_plumes = sum(label == 1 for label in train_dataset.labels)\n",
        "num_no_plumes = sum(label == 0 for label in train_dataset.labels)\n",
        "\n",
        "print(\"Number of training samples:\", len(train_dataset))\n",
        "print(f\"Number of plumes: {num_plumes}\")\n",
        "print(f\"Number of no plumes: {num_no_plumes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhegsm4NzSjd",
        "outputId": "2938f103-b826-4b16-8980-8b40cf57282c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 568\n",
            "Number of plumes: 284\n",
            "Number of no plumes: 284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We can check that our validation dataset is balanced between plume and no plume\n",
        "num_plumes = sum(label == 1 for label in val_dataset.labels)\n",
        "num_no_plumes = sum(label == 0 for label in val_dataset.labels)\n",
        "\n",
        "print(\"Number of validation samples:\", len(val_dataset))\n",
        "print(f\"Number of plumes: {num_plumes}\")\n",
        "print(f\"Number of no plumes: {num_no_plumes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYbFASyRcgJz",
        "outputId": "222d5733-5b32-4343-a96e-03311ac95c2f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of validation samples: 50\n",
            "Number of plumes: 25\n",
            "Number of no plumes: 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We can check that our test dataset is balanced between plume and no plume\n",
        "num_plumes = sum(label == 1 for label in test_dataset.labels)\n",
        "num_no_plumes = sum(label == 0 for label in test_dataset.labels)\n",
        "\n",
        "print(\"Number of validation samples:\", len(test_dataset))\n",
        "print(f\"Number of plumes: {num_plumes}\")\n",
        "print(f\"Number of no plumes: {num_no_plumes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pqRt0jpcqrA",
        "outputId": "ae1c28e1-6a82-4f34-8f6e-729e3d763a82"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of validation samples: 62\n",
            "Number of plumes: 31\n",
            "Number of no plumes: 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#WideResNet50"
      ],
      "metadata": {
        "id": "mqDHN24bbu8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the device for training (CPU or GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pre-trained ResNet50 model\n",
        "resnet50 = models.wide_resnet50_2(weights='Wide_ResNet50_2_Weights.IMAGENET1K_V2')\n",
        "\n",
        "# Modify the first layer to accept single-channel grayscale images\n",
        "resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "# Modify the last fully connected layer for binary classification with softmax activation\n",
        "num_classes = 2  # 2 classes: 1 or 0\n",
        "resnet50.fc = nn.Sequential(\n",
        "    nn.Linear(resnet50.fc.in_features, num_classes)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqkmXdkDbuts",
        "outputId": "f8eb3419-f010-438a-8d15-e011ed3c9279"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet50_2-9ba9bcbe.pth\n",
            "100%|██████████| 263M/263M [00:04<00:00, 58.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the model to the device\n",
        "resnet50 = resnet50.to(device)\n",
        "\n",
        "# Define the loss function (criterion)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = torch.optim.Adam(resnet50.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "K_GjwjV9bflN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 40\n",
        "from sklearn.metrics import classification_report, f1_score, roc_auc_score\n",
        "best_auc = 0.0\n",
        "# Training loop\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
        "    resnet50.train()  # Set the model to training mode\n",
        "\n",
        "    epoch_loss = 0.0  # Accumulator for epoch loss\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device, dtype=torch.float)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = resnet50(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate the loss\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # Compute the average loss for the epoch\n",
        "    epoch_loss /= len(train_loader)\n",
        "    tqdm.write(f\"Epoch {epoch+1}/{num_epochs} - Average Loss: {epoch_loss}\")\n",
        "\n",
        "    # Validation loop\n",
        "    resnet50.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    true_probabilities = []\n",
        "    predicted_probabilities = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device, dtype=torch.float)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = resnet50(images)\n",
        "            probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "            # Collect predicted probabilities and true labels\n",
        "            predicted_probabilities.extend(probabilities[:, 1].cpu().numpy())  # Assuming binary classification\n",
        "            true_probabilities.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Compute the AUC\n",
        "    auc = roc_auc_score(true_probabilities, predicted_probabilities)\n",
        "    print(f\"Validation AUC: {auc}\")\n",
        "\n",
        "    # Check if current accuracy is better than the previous best accuracy\n",
        "    if auc > best_auc:\n",
        "        best_auc = auc\n",
        "        torch.save(resnet50.state_dict(), f\"resnet50_{best_auc:.4f}.pth\")  # Save the model with AUC in the filename\n",
        "        print(\"Saved\")"
      ],
      "metadata": {
        "id": "dimSscoubfoW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d561d9ef-db27-4339-f51a-5bca9733339b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs:   0%|          | 0/40 [01:57<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40 - Average Loss: 0.7212073802947998\n",
            "Validation AUC: 0.7024\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:   2%|▎         | 1/40 [02:00<1:18:06, 120.16s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs:   2%|▎         | 1/40 [03:50<1:18:06, 120.16s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/40 - Average Loss: 0.6443524956703186\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:   5%|▌         | 2/40 [03:52<1:13:14, 115.65s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation AUC: 0.696\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs:   5%|▌         | 2/40 [05:43<1:13:14, 115.65s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/40 - Average Loss: 0.47982126143243575\n",
            "Validation AUC: 0.8592\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:   8%|▊         | 3/40 [05:47<1:10:57, 115.08s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs:   8%|▊         | 3/40 [07:44<1:10:57, 115.08s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/40 - Average Loss: 0.3208082723948691\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  10%|█         | 4/40 [07:46<1:10:01, 116.70s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation AUC: 0.5984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  10%|█         | 4/40 [09:44<1:10:01, 116.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/40 - Average Loss: 0.30529020643896526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpochs:  12%|█▎        | 5/40 [09:47<1:08:57, 118.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation AUC: 0.8048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  12%|█▎        | 5/40 [11:31<1:08:57, 118.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/40 - Average Loss: 0.34609031594461864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpochs:  15%|█▌        | 6/40 [11:33<1:04:47, 114.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation AUC: 0.7615999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  15%|█▌        | 6/40 [13:16<1:04:47, 114.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/40 - Average Loss: 0.25635839336448246\n",
            "Validation AUC: 0.9024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpochs:  18%|█▊        | 7/40 [13:23<1:01:59, 112.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  18%|█▊        | 7/40 [15:12<1:01:59, 112.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/40 - Average Loss: 0.15456599162684548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpochs:  20%|██        | 8/40 [15:15<59:56, 112.39s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation AUC: 0.824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  20%|██        | 8/40 [17:06<59:56, 112.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/40 - Average Loss: 0.1845846821864446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpochs:  22%|██▎       | 9/40 [17:09<58:20, 112.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation AUC: 0.7472000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test loop\n",
        "resnet50.eval()  # Set the model to evaluation mode\n",
        "\n",
        "true_probabilities = []\n",
        "predicted_probabilities = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device, dtype=torch.float)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = resnet50(images)\n",
        "        probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "        # Collect predicted probabilities and true labels\n",
        "        predicted_probabilities.extend(probabilities[:, 1].cpu().numpy())  # Assuming binary classification\n",
        "        true_probabilities.extend(labels.cpu().numpy())\n",
        "\n",
        "# Compute the ROC AUC for the test set\n",
        "test_auc = roc_auc_score(true_probabilities, predicted_probabilities)\n",
        "print(f\"Test ROC AUC: {test_auc}\")"
      ],
      "metadata": {
        "id": "KhbVO7ctcz8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Resnet101"
      ],
      "metadata": {
        "id": "t7hz8QuoUA4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the device for training (CPU or GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pre-trained ResNet101 model\n",
        "resnet101 = models.resnet101(weights='ResNet101_Weights.DEFAULT')\n",
        "\n",
        "# Modify the first layer to accept single-channel grayscale images\n",
        "resnet101.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "# Modify the last fully connected layer for binary classification with softmax activation\n",
        "num_classes = 2  # 2 classes: 1 or 0\n",
        "resnet101.fc = nn.Sequential(\n",
        "    nn.Linear(resnet101.fc.in_features, num_classes)\n",
        ")"
      ],
      "metadata": {
        "id": "zys8_x09SUuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the model to the device\n",
        "resnet101 = resnet101.to(device)\n",
        "\n",
        "# Define the loss function (criterion)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = torch.optim.Adam(resnet101.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 40"
      ],
      "metadata": {
        "id": "u3U_vxFEVKha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, f1_score, roc_auc_score\n",
        "best_auc = 0.0\n",
        "# Training loop\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
        "    resnet101.train()  # Set the model to training mode\n",
        "\n",
        "    epoch_loss = 0.0  # Accumulator for epoch loss\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device, dtype=torch.float)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = resnet101(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate the loss\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # Compute the average loss for the epoch\n",
        "    epoch_loss /= len(train_loader)\n",
        "    tqdm.write(f\"Epoch {epoch+1}/{num_epochs} - Average Loss: {epoch_loss}\")\n",
        "\n",
        "    # Validation loop\n",
        "    resnet101.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    true_probabilities = []\n",
        "    predicted_probabilities = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device, dtype=torch.float)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = resnet101(images)\n",
        "            probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "            # Collect predicted probabilities and true labels\n",
        "            predicted_probabilities.extend(probabilities[:, 1].cpu().numpy())  # Assuming binary classification\n",
        "            true_probabilities.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Compute the AUC\n",
        "    auc = roc_auc_score(true_probabilities, predicted_probabilities)\n",
        "    print(f\"Validation AUC: {auc}\")\n",
        "\n",
        "    # Check if current accuracy is better than the previous best accuracy\n",
        "    if auc > best_auc:\n",
        "        best_auc = auc\n",
        "        torch.save(resnet101.state_dict(), f\"resnet101_{best_auc:.4f}.pth\")  # Save the model with AUC in the filename\n",
        "        print(\"Saved\")"
      ],
      "metadata": {
        "id": "YDhUxfv0VNXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test loop\n",
        "resnet101.eval()  # Set the model to evaluation mode\n",
        "\n",
        "true_probabilities = []\n",
        "predicted_probabilities = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device, dtype=torch.float)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = resnet101(images)\n",
        "        probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "        # Collect predicted probabilities and true labels\n",
        "        predicted_probabilities.extend(probabilities[:, 1].cpu().numpy())  # Assuming binary classification\n",
        "        true_probabilities.extend(labels.cpu().numpy())\n",
        "\n",
        "# Compute the ROC AUC for the test set\n",
        "test_auc = roc_auc_score(true_probabilities, predicted_probabilities)\n",
        "print(f\"Test ROC AUC: {test_auc}\")"
      ],
      "metadata": {
        "id": "Ie28LiM5VQqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate submission file"
      ],
      "metadata": {
        "id": "LjezI004oQkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestCustomDataset(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        self.root_dir = root_dir\n",
        "        self.image_list = []  # List of image file paths\n",
        "\n",
        "        # Collect image file paths\n",
        "        image_names = os.listdir(root_dir)\n",
        "        tiff_image_names = [img_name for img_name in image_names if img_name.lower().endswith('.tiff') or img_name.lower().endswith('.tif')]\n",
        "        self.image_list = [os.path.join(root_dir, img_name) for img_name in tiff_image_names]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_list[idx]\n",
        "\n",
        "        # Load and transform the test image\n",
        "        image = Image.open(image_path)\n",
        "        image = image.resize((64, 64))  # Resize to 64x64\n",
        "\n",
        "        transform = transforms.Compose([transforms.ToTensor()])\n",
        "        image = transform(image)\n",
        "\n",
        "        return image, image_path  # Also return the image path for reference\n",
        "\n",
        "test_dir = \"/content/drive/My Drive/data/test data/images\"\n",
        "test_dataset = TestCustomDataset(test_dir)\n",
        "\n",
        "# Create a data loader for the test dataset\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "# Verify the test data loader\n",
        "for images, image_paths in test_loader:\n",
        "    print(f\"Test batch - Images: {images.shape}\")\n",
        "    break\n"
      ],
      "metadata": {
        "id": "eji_mxrDoQFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define a function to make predictions\n",
        "def predict_image(model, image):\n",
        "    # Preprocess the image as needed, e.g., resizing, normalizing\n",
        "    # You may need to convert the image to a PyTorch tensor\n",
        "    # Make predictions using the model\n",
        "    # Ensure that the model is in evaluation mode\n",
        "    resnet101.eval()\n",
        "    with torch.no_grad():\n",
        "        image = image.to(device, dtype=torch.float)\n",
        "        outputs = resnet101(image)\n",
        "        probabilities = torch.softmax(outputs, dim=1)  # Assuming binary classification\n",
        "    return probabilities\n",
        "\n",
        "# Create a DataFrame to store results\n",
        "submission_data = []\n",
        "path_to_remove = '/content/drive/My Drive/data/test data/images/'\n",
        "\n",
        "# Iterate through the test data\n",
        "for images, image_paths in test_loader:\n",
        "    # Make predictions for the batch of images\n",
        "    probabilities = predict_image(resnet101, images)\n",
        "\n",
        "    # Add image paths and predicted probabilities to the DataFrame\n",
        "    for i in range(len(image_paths)):\n",
        "        shortened_path = image_paths[i].replace(path_to_remove, '')\n",
        "        submission_data.append([shortened_path, probabilities[i][1].item()])\n",
        "\n",
        "# Create a DataFrame with the results\n",
        "submission_df = pd.DataFrame(submission_data, columns=[\"path\", \"label\"])\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "submission_df.to_csv(\"submission_test_file.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "fnuyoVU4jWUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qbpt-Dj-sdK6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}